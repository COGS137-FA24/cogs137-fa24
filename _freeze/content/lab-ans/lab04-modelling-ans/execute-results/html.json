{
  "hash": "8f461c1b1911b739b504fe702200c573",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lab 04 - Modelling (Ans)\"\nauthor: \"Sean Trott\"\noutput: \n  html: \n    highlight: pygments\n    preview-links: auto\n---\n\n\n## Getting Started\n\n### Load packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\n```\n:::\n\n\n### Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nevals <- read_csv(\"data/evals-mod.csv\")\n```\n:::\n\n\n## Part 1\n\n### Exercise 1\n\nFirst, we use `rowwise` to group `evals` by each *row*. We then use `mutate` to compute a new variable (`bty_avg`) corresponding to the average of the six beauty scores.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nevals <- evals |>\n  rowwise() |>\n  mutate(bty_avg = mean( c( bty_f1lower, bty_f1upper,\n                            bty_f2upper, bty_m1lower,\n                            bty_m1upper, bty_m2upper) ))\n```\n:::\n\n\n## Part 2\n\n### Exercise 2\n\nThe distribution is slightly left-skewed, i.e., many scores are on the higher side (between 4-5) with a longer tail going to the left.\n\nThis is further corroborrated by the fact that the mean is lower than the median. Given that the mean is more affected by skew than the median, this is what we'd expect with negatively skewed data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nevals |>\n  ggplot(aes(x = score))+\n  geom_histogram() +\n  theme_bw()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](lab04-modelling-ans_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n\n```{.r .cell-code}\nevals |>\n  summarise(mean = mean(score),\n            median = median(score),\n            sd = sd(score))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 463 × 3\n    mean median    sd\n   <dbl>  <dbl> <dbl>\n 1   4.7    4.7    NA\n 2   4.1    4.1    NA\n 3   3.9    3.9    NA\n 4   4.8    4.8    NA\n 5   4.6    4.6    NA\n 6   4.3    4.3    NA\n 7   2.8    2.8    NA\n 8   4.1    4.1    NA\n 9   3.4    3.4    NA\n10   4.5    4.5    NA\n# ℹ 453 more rows\n```\n\n\n:::\n:::\n\n\n### Exercise 3\n\nIt seems like there's a slight positive relationship between `bty_avg` and `score`, though it's hard to tell given that many points overlap and form \"bands\" along particular values (e.g., many teachers have the same `score`).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nevals |>\n  ggplot(aes(x = bty_avg,\n             y = score))+\n  geom_point() +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](lab04-modelling-ans_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n### Exercise 4\n\nOne way to deal with the above is to add *jitter* to the plot, which reveals that certain clusters of points were either larger or smaller than initially thought. (Another apprpoach would be to change the `alpha` of `geom_point`, allowing us to detect denser clusters.)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nevals |>\n  ggplot(aes(x = bty_avg,\n             y = score))+\n  geom_jitter() +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](lab04-modelling-ans_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n## Part 3\n\n### Exercise 5\n\nAccording to the model, the linear equation would be as follows:\n\n$\\hat{y} = 3.88 + 0.07*X$\n\nWhere $X$ is `bty_avg`.\n\nWe use `broom::tidy` to transform the model object into a tidy dataframe.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_bty <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(score ~ bty_avg, data = evals)\n\nm_bty |>\n  tidy() |>\n  select(term, estimate)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  term        estimate\n  <chr>          <dbl>\n1 (Intercept)   3.88  \n2 bty_avg       0.0666\n```\n\n\n:::\n:::\n\n\n### Exercise 6\n\n\n::: {.cell}\n\n```{.r .cell-code}\nevals |>\n  ggplot(aes(x = bty_avg,\n             y = score))+\n  geom_point() +\n  geom_smooth(method = \"lm\", \n              color = \"orange\",\n              se = FALSE) +\n  theme_bw()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](lab04-modelling-ans_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n### Exercise 7\n\nProfessors with higher average beauty ratings also tend to receive higher teaching scores.\n\nThe slope is approximately 0.07, which means that for every 1-unit increase in beauty rating (i.e., from 4 to 5), we can expect that a professor will receive .07 higher teaching scores (with a \\~0.02 standard error).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_bty |>\n  tidy() |>\n  filter(term == \"bty_avg\") |>\n  select(term, estimate, std.error)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 3\n  term    estimate std.error\n  <chr>      <dbl>     <dbl>\n1 bty_avg   0.0666    0.0163\n```\n\n\n:::\n:::\n\n\n### Exercise 8\n\nThe intercept is 3.88. This is the estimated `score` for professors with a beauty score of 0, i.e., it is the value of $\\hat{y}$ when the regression line crosses $x = 0$.\n\nThis may or may not make sense; given that possible beauty scores ranged from 1-6, it is a little strange to imagine a scenario where the beauty score is 0 (and it would be even stranger to imagine scenarios where the beauty scores is *negative*).\n\nOn the other hand, it is not inconsistent with other features of the data: the mean score, for example, is 4.17, so it makes sense that the intercept of a linear model would be slightly lower than the mean, allowing the explanatory variable to account for increases in score throughout the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_bty |>\n  tidy() |>\n  filter(term == \"(Intercept)\") |>\n  select(term, estimate, std.error)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 3\n  term        estimate std.error\n  <chr>          <dbl>     <dbl>\n1 (Intercept)     3.88    0.0761\n```\n\n\n:::\n:::\n\n\n### Exercise 9\n\nHere, we identify the $R^2$ of the model using `glance`, which identifies **model-level** characteristics.\n\nThe value is 0.0350, which means that our explanatory variable accounts for roughly 3.5% of the variance in our response variable.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_bty |>\n  glance() |>\n  select(r.squared)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 1\n  r.squared\n      <dbl>\n1    0.0350\n```\n\n\n:::\n:::\n\n\n## Part 4\n\n### Exercise 10\n\nThe linear equation would be as follows:\n\n$\\hat{y} = 4.09 + 0.142*X$\n\nWhere $X = 1$ for `male` professors and $X = 0$ for `female` professors. In other words, the *intercept* corresponds to the mean score for `female` professors, while the *slope* tells us the difference in mean between the `female` average and the `male` average.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_gen <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit( score ~ gender, data = evals)\n\nm_gen |>\n  tidy()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 5\n  term        estimate std.error statistic p.value\n  <chr>          <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)    4.09     0.0387    106.   0      \n2 gendermale     0.142    0.0508      2.78 0.00558\n```\n\n\n:::\n:::\n\n\n### Exercise 11\n\nAs specified above, the slope coefficient for the $X$ term signifies the difference in means between `male` and `female` professors.\n\n### Exercise 12\n\nHere, the model equation would look as follows:\n\n$\\hat{y} = 4.28 + -0.13*X_1 + -0.145*X_2$\n\nWhere $X_1 = 1$ for `tenure track` professors and 0 for all else, and $X_2 = 1$ for `tenured` professors and 0 for all else.\n\nIn other words: the intercept tells us the mean for *teaching* professors, and the two slope coefficients tell us the difference between that mean and the two other levels of `rank`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(evals$rank)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n    teaching tenure track      tenured \n         102          108          253 \n```\n\n\n:::\n\n```{.r .cell-code}\nm_rank <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(score ~ rank, data = evals)\n\nm_rank |>\n  tidy()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 5\n  term             estimate std.error statistic   p.value\n  <chr>               <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)         4.28     0.0537     79.9  1.02e-271\n2 ranktenure track   -0.130    0.0748     -1.73 8.37e-  2\n3 ranktenured        -0.145    0.0636     -2.28 2.28e-  2\n```\n\n\n:::\n:::\n\n\n### Exercise 13\n\nHere, we use the `factor` command (within `mutate`) to reorder the levels of `rank` such that `tenure track` is the first level.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nevals <- evals |>\n  mutate(rank_relevel = fct_relevel(factor(rank), c(\"tenure track\",\n                                                    \"teaching\",\n                                                    \"tenured\")))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: There were 463 warnings in `mutate()`.\nThe first warning was:\nℹ In argument: `rank_relevel = fct_relevel(factor(rank), c(\"tenure track\",\n  \"teaching\", \"tenured\"))`.\nℹ In row 1.\nCaused by warning:\n! 2 unknown levels in `f`: teaching and tenured\nℹ Run `dplyr::last_dplyr_warnings()` to see the 462 remaining warnings.\n```\n\n\n:::\n:::\n\n\n### Exercise 14\n\nThis model has the same structure as the previous model using `rank`, but it has reordered the levels of `rank` (for `rank_relevel`) such that `tenure track` is now first.\n\nThis means that the *intercept* should now be interpreted as the mean score for `tenure track` professors, and the coefficients represent the difference in means for `teaching` and `tenured` professors, respectively.\n\n$\\hat{y} = 4.15 + 0.13*X_1 + -0.0155*X_2$\n\nWhere $X_1 = 1$ for `teaching` professors and 0 for all else; and $X_2 = 1$ for `tenured` professors and 0 for all else.\n\nWe can compare tehse to the coefficients for the previous model, where `teaching` was the baseline: in both cases, we see that the difference between `teaching` and `tenure track` is 0.13 (just in opposite directions, depending on the baseline).\n\nThe $R^2$ of the model is 0.0116 in both cases. In other words, the model explains approximately 1.16% of the variance in `score`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_rank_relevel <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(score ~ rank_relevel, data = evals)\n\n\nm_rank_relevel |>\n  tidy()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 5\n  term                 estimate std.error statistic   p.value\n  <chr>                   <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)            4.15      0.0521    79.7   2.58e-271\n2 rank_releveltenured   -0.0155    0.0623    -0.249 8.04e-  1\n3 rank_relevelteaching   0.130     0.0748     1.73  8.37e-  2\n```\n\n\n:::\n\n```{.r .cell-code}\nm_rank_relevel |>\n  glance() |>\n  select(r.squared)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 1\n  r.squared\n      <dbl>\n1    0.0116\n```\n\n\n:::\n:::\n\n\n### Exercise 15\n\n\n::: {.cell}\n\n```{.r .cell-code}\nevals <- evals |>\n  mutate(tenure_eligible = case_when(\n    rank == \"teaching\" ~ \"no\",\n    TRUE ~ \"yes\"\n  ))\n\n## Double check\ntable(evals$rank, evals$tenure_eligible)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              \n                no yes\n  teaching     102   0\n  tenure track   0 108\n  tenured        0 253\n```\n\n\n:::\n:::\n\n\n### Exercise 16\n\nThe linear equation is as follows:\n\n$\\hat{y} = 4.28 + -0.141*X_1$\n\nWhere $X_1 = 1$ for tenure eligible professors and $X_1 = 0$ for non-tenure-eligible professors.\n\nThus, this means that the mean `score` for non-tenure-eligible professors is 4.28, and professors that *are* tenure eligible can expect a score that's -0.141 lower, on average.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_tenure_eligible <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(score ~ tenure_eligible, data = evals)\n\nm_tenure_eligible |>\n  tidy()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 5\n  term               estimate std.error statistic   p.value\n  <chr>                 <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)           4.28     0.0536     79.9  2.72e-272\n2 tenure_eligibleyes   -0.141    0.0607     -2.32 2.10e-  2\n```\n\n\n:::\n:::\n\n\nWe can also calculate the $R^2$, and we see that it is 0.0115. In other words, the model explains approximately 1.15% of the variance in `score`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_tenure_eligible |>\n  glance()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n      <dbl>         <dbl> <dbl>     <dbl>   <dbl> <dbl>  <dbl> <dbl> <dbl>\n1    0.0115       0.00935 0.541      5.36  0.0210     1  -372.  750.  762.\n# ℹ 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>\n```\n\n\n:::\n:::\n",
    "supporting": [
      "lab04-modelling-ans_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}