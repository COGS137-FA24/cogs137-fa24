{
  "hash": "96e40bf54165543a2a75c08c800a7679",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"13-cs02-analysis\"\nauthor: \"Professor Shannon Ellis\"\ndate: \"2024-11-19\"\n\nformat:\n  html: \n    output-file: 13-cs02-analysis.html\n  revealjs:\n    output-file: 13-cs02-analysis-slides.html\n    css: slides.css\n---\n\n::: {.cell}\n\n:::\n\n\n# CS02: Predicting Air Pollution (Analysis) {background-color=\"#92A86A\"}\n\n## Q&A {.smaller}\n\n> Q: \"First, in our CS02, is our prediction US annual average air pollution concentrations based on \"\"value\"\"? Is this going to be our outcome, as it was in class? \\\n> A: `value` will be our outcome. In this set of notes, we'll discuss how to directly answer our question using machine learning. \n\n> Q: How do we decide whether to use main effects of interaction effects? Do we have to try both and compare r square values?\\\n> A: Well, we only include an interaction term if it actually makes sense for what we're modelling, if the interaction term's inclusion makes logical sense - meaning it could impact the relationship between the other predictor and outcome. Without that, it doesn't make sense to include an interaction term, as the simplest model (no interaction) is preferred overall. \n\n> Q: San you redefine the differences between main vs. interaction effects? what are the pros and cons of each?\\\n> A: In a main effects model, we're assuming the relationship between the predictor and outcome **does not vary** (is not impacted) by the second predictor (different y-intercepts; same slope/rate of change). In an interaction effects model we're assuming the second predictor *does* impact the primary predictor and outcomes relationship. (different y-intercepts; different slopes). Con of interaction is that it adds an additional term into the model and is more difficult to interpret. So, you only want to go for an interaction effects model *if it truly does a better job capturing the underlying relationships in the data*.\n\n> Q: I wonder if we will go over logistic regressions, or k-clusters, or any other form of ML algorithms .\\\n> A: We're not going to do logistic regression this quarter, but will introduce ML algorithms in this set of notes!\n\n## Course Announcements\n\n- **Lab07** due Thursday\n- **HW03** due Friday\n- **CS02** due Monday\n- **Final Project - rough draft** due Monday\n\nNotes: \n\n- **Lab06** scores/feedback posted\n- **CS01** scores/feedback posted\n  - Feedback as issue on repo\n  - If your score on CS02 is higher than CS01 that score will automatically be used for both CS01 and CS02\n- Class Thursday will be time to work on CS02\n\n\n## Progress Check-in\n\n[❓ Where should you and your group be for CSO2 completion?]{style=\"background-color: #ADD8E6\"}\n\n. . . \n\n[❓ Where should you be at right now for your final project? What should you have done for rough draft on Monday?]{style=\"background-color: #ADD8E6\"}\n\n\n# Question {background-color=\"#92A86A\"}\n\n> With what accuracy can we predict US annual average air pollution concentrations?\n\n\n# Analysis {background-color=\"#92A86A\"}\n\n## Building our `tidymodels` knowledge:\n\n![](images/14/Updated_tidymodels_basics.png)\n\n## The Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\npm <- read_csv(\"OCS_data/data/raw/pm25_data.csv\")\n\n# Converting to factors\npm <- pm |>\n  mutate(across(c(id, fips, zcta), as.factor)) \n```\n:::\n\n\n## Data Splitting\n\n<p align=\"center\">\n\n<img src=\"images/17/split.png\" width=\"800\"/>\n\n</p>\n\n. . .\n\nSpecify the split:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\npm_split <- rsample::initial_split(data = pm, prop = 2/3)\npm_split\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<Training/Testing/Total>\n<584/292/876>\n```\n\n\n:::\n:::\n\n\n-   `set.seed` \\<- ensures we all get the exact same random split\n-   output displayed: `<training data sample number, testing data sample number, original sample number>`\n\nMore on how people decide what proportions to use for data splitting [here](https://onlinelibrary.wiley.com/doi/full/10.1002/sam.11583)\n\n\n\n## Split the Data  \n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_pm <- rsample::training(pm_split)\ntest_pm <- rsample::testing(pm_split)\n \n# Scroll through the output!\ncount(train_pm, state)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 49 × 2\n   state                    n\n   <chr>                <int>\n 1 Alabama                 13\n 2 Arizona                 12\n 3 Arkansas                 8\n 4 California              55\n 5 Colorado                10\n 6 Connecticut             12\n 7 Delaware                 3\n 8 District Of Columbia     2\n 9 Florida                 22\n10 Georgia                 20\n# ℹ 39 more rows\n```\n\n\n:::\n:::\n\n\n[❓ What do you observe about the output?]{style=\"background-color: #ADD8E6\"}\n\n## Pre-processing: `recipe()` + `bake()`\n\nNeed to:\n\n-   specify predictors vs. outcome\n-   scale variables\n-   remove redundant variables (feature engineering)\n\n. . .\n\n`recipe` provides a standardized format for a sequence of steps for pre-processing the data\n\n. . .\n\n<p align=\"center\">\n\n<img src=\"images/17/Starting_a_recipe_recipes1.png\" width=\"550\"/>\n\n</p>\n\n## Step 1: Specify variable roles\n\nThe simplest approach...\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimple_rec <- train_pm |>\n  recipes::recipe(value ~ .)\n\nsimple_rec\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Recipe ──────────────────────────────────────────────────────────────────────\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Inputs \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nNumber of variables by role\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\noutcome:    1\npredictor: 49\n```\n\n\n:::\n:::\n\n\n. . .\n\n...but we need to specify which column includes ID information\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimple_rec <- train_pm |>\n  recipes::recipe(value ~ .) |>\n  recipes::update_role(id, new_role = \"id variable\")\n\nsimple_rec\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Recipe ──────────────────────────────────────────────────────────────────────\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Inputs \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nNumber of variables by role\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\noutcome:      1\npredictor:   48\nid variable:  1\n```\n\n\n:::\n:::\n\n\n. . .\n\n...and which are our predictors and which is our outcome\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimple_rec <- recipe(train_pm) |>\n    update_role(everything(), new_role = \"predictor\") |>\n    update_role(value, new_role = \"outcome\") |>\n    update_role(id, new_role = \"id variable\")\n\nsimple_rec\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Recipe ──────────────────────────────────────────────────────────────────────\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Inputs \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nNumber of variables by role\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\noutcome:      1\npredictor:   48\nid variable:  1\n```\n\n\n:::\n:::\n\n\n[❓ Can someone summarize what this code is specifying?]{style=\"background-color: #ADD8E6\"}\n\n. . .\n\nSummarizing our recipe thus far:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(simple_rec)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 50 × 4\n   variable type      role        source  \n   <chr>    <list>    <chr>       <chr>   \n 1 id       <chr [3]> id variable original\n 2 value    <chr [2]> outcome     original\n 3 fips     <chr [3]> predictor   original\n 4 lat      <chr [2]> predictor   original\n 5 lon      <chr [2]> predictor   original\n 6 state    <chr [3]> predictor   original\n 7 county   <chr [3]> predictor   original\n 8 city     <chr [3]> predictor   original\n 9 CMAQ     <chr [2]> predictor   original\n10 zcta     <chr [3]> predictor   original\n# ℹ 40 more rows\n```\n\n\n:::\n:::\n\n\n## Step 2: Pre-process with `step*()` \n\n![](images/17/Making_a_recipe_recipes2.png)\n\n## Steps {.smaller}\n\n<u>There are step functions for a variety of purposes:</u>\n\n1.  [**Imputation**](https://en.wikipedia.org/wiki/Imputation_(statistics)){target=\"_blank\"} -- filling in missing values based on the existing data\n2.  [**Transformation**](https://en.wikipedia.org/wiki/Data_transformation_(statistics)){target=\"_blank\"} -- changing all values of a variable in the same way, typically to make it more normal or easier to interpret\n3.  [**Discretization**](https://en.wikipedia.org/wiki/Discretization_of_continuous_features){target=\"_blank\"} -- converting continuous values into discrete or nominal values - binning for example to reduce the number of possible levels (However this is generally not advisable!)\n4.  [**Encoding / Creating Dummy Variables**](https://en.wikipedia.org/wiki/Dummy_variable_(statistics)){target=\"_blank\"} -- creating a numeric code for categorical variables ([**More on one-hot and Dummy Variables encoding**](https://medium.com/p/b5840be3c41a/responses/show){target=\"_blank\"})\n5.  [**Data type conversions**](https://cran.r-project.org/web/packages/hablar/vignettes/convert.html){target=\"_blank\"} -- which means changing from integer to factor or numeric to date etc.\n6.  [**Interaction**](https://statisticsbyjim.com/regression/interaction-effects/){target=\"_blank\"} term addition to the model -- which means that we would be modeling for predictors that would influence the capacity of each other to predict the outcome\n7.  [**Normalization**](https://en.wikipedia.org/wiki/Normalization_(statistics)){target=\"_blank\"} -- centering and scaling the data to a similar range of values\n8.  [**Dimensionality Reduction/ Signal Extraction**](https://en.wikipedia.org/wiki/Dimensionality_reduction){target=\"_blank\"} -- reducing the space of features or predictors to a smaller set of variables that capture the variation or signal in the original variables (ex. Principal Component Analysis and Independent Component Analysis)\n9.  **Filtering** -- filtering options for removing variables (ex. remove variables that are highly correlated to others or remove variables with very little variance and therefore likely little predictive capacity)\n10. [**Row operations**](https://tartarus.org/gareth/maths/Linear_Algebra/row_operations.pdf){target=\"_blank\"} -- performing functions on the values within the rows (ex. rearranging, filtering, imputing)\n11. **Checking functions** -- Gut checks to look for missing values, to look at the variable classes etc.\n\n**This [link](https://tidymodels.github.io/recipes/reference/index.html){target=\"_blank\"} and this [link](https://cran.r-project.org/web/packages/recipes/recipes.pdf){target=\"_blank\"} show the many options for recipe step functions.**\n\n## Selecting Variables {.smaller}\n\nThere are several ways to select what variables to apply steps to:\n\n1.  Using `tidyselect` methods: `contains()`, `matches()`, `starts_with()`, `ends_with()`, `everything()`, `num_range()`\\\n2.  Using the type: `all_nominal()`, `all_numeric()` , `has_type()`\n3.  Using the role: `all_predictors()`, `all_outcomes()`, `has_role()`\n4.  Using the name - use the actual name of the variable/variables of interest\n\n## One-hot Encoding\n\nOne-hot encoding categorical variables:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimple_rec |>\n  step_dummy(state, county, city, zcta, one_hot = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Recipe ──────────────────────────────────────────────────────────────────────\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Inputs \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nNumber of variables by role\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\noutcome:      1\npredictor:   48\nid variable:  1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Operations \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• Dummy variables from: state, county, city, zcta\n```\n\n\n:::\n:::\n\n\n[❓ Can anyone explain what one-hot encoding does?]{style=\"background-color: #ADD8E6\"}\n\n. . .\n\n-   `fips` includes numeric code for state and county, so it's another way to specify county\n-   so, we'll change `fips`' role\n-   we get to decide what to call it (`\"county id\"`)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimple_rec |>\n  update_role(\"fips\", new_role = \"county id\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Recipe ──────────────────────────────────────────────────────────────────────\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Inputs \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nNumber of variables by role\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\noutcome:      1\npredictor:   47\ncounty id:    1\nid variable:  1\n```\n\n\n:::\n:::\n\n\n. . .\n\nRemoving highly correlated variables:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimple_rec |>\n  step_corr(all_predictors(), - CMAQ, - aod)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Recipe ──────────────────────────────────────────────────────────────────────\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Inputs \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nNumber of variables by role\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\noutcome:      1\npredictor:   48\nid variable:  1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Operations \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• Correlation filter on: all_predictors(), -CMAQ, -aod\n```\n\n\n:::\n:::\n\n\n-   specifying to KEEP `CMAQ` and `aod`\n\n. . .\n\nRemoving variables with non-zero variance:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimple_rec |>\n  step_nzv(all_predictors(), - CMAQ, - aod)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Recipe ──────────────────────────────────────────────────────────────────────\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Inputs \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nNumber of variables by role\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\noutcome:      1\npredictor:   48\nid variable:  1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Operations \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• Sparse, unbalanced variable filter on: all_predictors(), -CMAQ, -aod\n```\n\n\n:::\n:::\n\n\n## Putting our `recipe` together\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimple_rec <- simple_rec |> \n  update_role(\"fips\", new_role = \"county id\") |>\n  step_dummy(state, county, city, zcta, one_hot = TRUE) |>\n  step_corr(all_predictors(), - CMAQ, - aod)|>\n  step_nzv(all_predictors(), - CMAQ, - aod)\n  \nsimple_rec\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Recipe ──────────────────────────────────────────────────────────────────────\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Inputs \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nNumber of variables by role\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\noutcome:      1\npredictor:   47\ncounty id:    1\nid variable:  1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Operations \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• Dummy variables from: state, county, city, zcta\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• Correlation filter on: all_predictors(), -CMAQ, -aod\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• Sparse, unbalanced variable filter on: all_predictors(), -CMAQ, -aod\n```\n\n\n:::\n:::\n\n\nNote: order of steps matters\n\n## Step 3: Running the pre-processing (`prep`) {.smaller}\n\nThere are some important arguments to know about:\n\n1.  `training` - you must supply a training data set to estimate parameters for pre-processing operations (recipe steps) - this may already be included in your recipe - as is the case for us\n2.  `fresh` - if `fresh=TRUE`, will retrain and estimate parameters for any previous steps that were already prepped if you add more steps to the recipe (default is `FALSE`)\n3.  `verbose` - if `verbose=TRUE`, shows the progress as the steps are evaluated and the size of the pre-processed training set (default is `FALSE`)\n4.  `retain` - if `retain=TRUE`, then the pre-processed training set will be saved within the recipe (as template). This is good if you are likely to add more steps and do not want to rerun the `prep()` on the previous steps. However this can make the recipe size large. This is necessary if you want to actually look at the pre-processed data (default is `TRUE`)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprepped_rec <- prep(simple_rec, \n                    verbose = TRUE, \n                    retain = TRUE )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\noper 1 step dummy [training] \noper 2 step corr [training] \noper 3 step nzv [training] \nThe retained training set is ~ 0.26 Mb  in memory.\n```\n\n\n:::\n\n```{.r .cell-code}\nnames(prepped_rec)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"var_info\"       \"term_info\"      \"steps\"          \"template\"      \n [5] \"levels\"         \"retained\"       \"requirements\"   \"tr_info\"       \n [9] \"orig_lvls\"      \"last_term_info\"\n```\n\n\n:::\n:::\n\n\n. . .\n\nThis output includes a lot of information:\n\n1.  the `steps` that were run\\\n2.  the original variable info (`var_info`)\\\n3.  the updated variable info after pre-processing (`term_info`)\n4.  the new `levels` of the variables\n5.  the original levels of the variables (`orig_lvls`)\n6.  info about the training data set size and completeness (`tr_info`)\n\n## Step 4: Extract pre-processed training data using `bake()` {.smaller}\n\n![](images/17/training_preprocessing_recipes3.png)\n\n`bake()`: apply our modeling steps (in this case just pre-processing on the training data) and see what it would do the data\n\n. . .\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbaked_train <- bake(prepped_rec, new_data = NULL)\n\nglimpse(baked_train)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 584\nColumns: 37\n$ id                          <fct> 18003.0004, 55041.0007, 6065.1003, 39009.0…\n$ value                       <dbl> 11.699065, 6.956780, 13.289744, 10.742000,…\n$ fips                        <fct> 18003, 55041, 6065, 39009, 39061, 24510, 6…\n$ lat                         <dbl> 41.09497, 45.56300, 33.94603, 39.44217, 39…\n$ lon                         <dbl> -85.10182, -88.80880, -117.40063, -81.9088…\n$ CMAQ                        <dbl> 10.383231, 3.411247, 11.404085, 7.971165, …\n$ zcta_area                   <dbl> 16696709, 370280916, 41957182, 132383592, …\n$ zcta_pop                    <dbl> 21306, 4141, 44001, 1115, 6566, 934, 41192…\n$ imp_a500                    <dbl> 28.9783737, 0.0000000, 30.3901384, 0.00000…\n$ imp_a15000                  <dbl> 13.0547959, 0.3676404, 23.7457506, 0.33079…\n$ county_area                 <dbl> 1702419942, 2626421270, 18664696661, 13043…\n$ county_pop                  <dbl> 355329, 9304, 2189641, 64757, 802374, 6209…\n$ log_dist_to_prisec          <dbl> 6.621891, 8.415468, 7.419762, 6.344681, 5.…\n$ log_pri_length_5000         <dbl> 8.517193, 8.517193, 10.150514, 8.517193, 9…\n$ log_pri_length_25000        <dbl> 12.77378, 10.16440, 13.14450, 10.12663, 13…\n$ log_prisec_length_500       <dbl> 6.214608, 6.214608, 6.214608, 6.214608, 7.…\n$ log_prisec_length_1000      <dbl> 9.240294, 7.600902, 7.600902, 8.793450, 8.…\n$ log_prisec_length_5000      <dbl> 11.485093, 9.425537, 10.155961, 10.562382,…\n$ log_prisec_length_10000     <dbl> 12.75582, 11.44833, 11.59563, 11.69093, 12…\n$ log_nei_2008_pm10_sum_10000 <dbl> 4.91110140, 3.86982666, 4.03184660, 0.0000…\n$ log_nei_2008_pm10_sum_15000 <dbl> 5.399131, 3.883689, 5.459257, 0.000000, 6.…\n$ log_nei_2008_pm10_sum_25000 <dbl> 5.816047, 3.887264, 6.884537, 3.765635, 6.…\n$ popdens_county              <dbl> 208.719947, 3.542463, 117.314577, 49.64834…\n$ popdens_zcta                <dbl> 1276.059851, 11.183401, 1048.711994, 8.422…\n$ nohs                        <dbl> 4.3, 5.1, 3.7, 4.8, 2.1, 0.0, 2.5, 7.7, 0.…\n$ somehs                      <dbl> 6.7, 10.4, 5.9, 11.5, 10.5, 0.0, 4.3, 7.5,…\n$ hs                          <dbl> 31.7, 40.3, 17.9, 47.3, 30.0, 0.0, 17.8, 2…\n$ somecollege                 <dbl> 27.2, 24.1, 26.3, 20.0, 27.1, 0.0, 26.1, 2…\n$ associate                   <dbl> 8.2, 7.4, 8.3, 3.1, 8.5, 71.4, 13.2, 7.6, …\n$ bachelor                    <dbl> 15.0, 8.6, 20.2, 9.8, 14.2, 0.0, 23.4, 17.…\n$ grad                        <dbl> 6.8, 4.2, 17.7, 3.5, 7.6, 28.6, 12.6, 12.3…\n$ pov                         <dbl> 13.500, 18.900, 6.700, 14.400, 12.500, 3.5…\n$ hs_orless                   <dbl> 42.7, 55.8, 27.5, 63.6, 42.6, 0.0, 24.6, 3…\n$ urc2006                     <dbl> 3, 6, 1, 5, 1, 1, 2, 1, 2, 6, 4, 4, 4, 4, …\n$ aod                         <dbl> 54.11111, 31.16667, 83.12500, 33.36364, 50…\n$ state_California            <dbl> 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, …\n$ city_Not.in.a.city          <dbl> 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, …\n```\n\n\n:::\n:::\n\n\n-   `new_data = NULL` specifies that we're not (yet) looking at our testing data\n-   We only have 36 variables (33 predictors + 2 id variables + outcome)\n-   categorical variables (`state`) are gone (one-hot encoding)\n-   `state_California` remains - only state with nonzero variance (largest \\# of monitors)\n\n## Step 5: Extract pre-processed testing data using `bake()` {.smaller}\n\n> `bake()` takes a trained recipe and applies the operations to a data set to create a design matrix. For example: it applies the centering to new data sets using these means used to create the recipe. - `tidymodels` documentation\n\n. . .\n\nTypically, you want to avoid using your testing data...but our data set is not that large and NA values in our testing dataset could cause issues later on.\n\n<p align=\"center\">\n\n<img src=\"images/17/testing_preprocessing_recipes4.png\" width=\"550\"/>\n\n</p>\n\n. . .\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbaked_test_pm <- recipes::bake(prepped_rec, new_data = test_pm)\nglimpse(baked_test_pm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 292\nColumns: 37\n$ id                          <fct> 1033.1002, 1055.001, 1069.0003, 1073.0023,…\n$ value                       <dbl> 11.212174, 12.375394, 10.508850, 15.591017…\n$ fips                        <fct> 1033, 1055, 1069, 1073, 1073, 1073, 1073, …\n$ lat                         <dbl> 34.75878, 33.99375, 31.22636, 33.55306, 33…\n$ lon                         <dbl> -87.65056, -85.99107, -85.39077, -86.81500…\n$ CMAQ                        <dbl> 9.402679, 9.241744, 9.121892, 10.235612, 1…\n$ zcta_area                   <dbl> 16716984, 154069359, 162685124, 26929603, …\n$ zcta_pop                    <dbl> 9042, 20045, 30217, 9010, 16140, 3699, 137…\n$ imp_a500                    <dbl> 19.17301038, 16.49307958, 19.13927336, 41.…\n$ imp_a15000                  <dbl> 5.2472094, 5.1612102, 4.7401296, 17.452484…\n$ county_area                 <dbl> 1534877333, 1385618994, 1501737720, 287819…\n$ county_pop                  <dbl> 54428, 104430, 101547, 658466, 658466, 194…\n$ log_dist_to_prisec          <dbl> 5.760131, 5.261457, 7.112373, 6.600958, 6.…\n$ log_pri_length_5000         <dbl> 8.517193, 9.066563, 8.517193, 11.156977, 1…\n$ log_pri_length_25000        <dbl> 10.15769, 12.01356, 10.12663, 12.98762, 12…\n$ log_prisec_length_500       <dbl> 8.611945, 8.740680, 6.214608, 6.214608, 6.…\n$ log_prisec_length_1000      <dbl> 9.735569, 9.627898, 7.600902, 9.075921, 8.…\n$ log_prisec_length_5000      <dbl> 11.770407, 11.728889, 12.298627, 12.281645…\n$ log_prisec_length_10000     <dbl> 12.840663, 12.768279, 12.994141, 13.278416…\n$ log_nei_2008_pm10_sum_10000 <dbl> 6.69187313, 4.43719884, 0.92888890, 8.2097…\n$ log_nei_2008_pm10_sum_15000 <dbl> 6.70127741, 4.46267932, 3.67473904, 8.6488…\n$ log_nei_2008_pm10_sum_25000 <dbl> 7.148858, 4.678311, 3.744629, 8.858019, 8.…\n$ popdens_county              <dbl> 35.460814, 75.367038, 67.619664, 228.77763…\n$ popdens_zcta                <dbl> 540.8870404, 130.1037411, 185.7391706, 334…\n$ nohs                        <dbl> 7.3, 4.3, 5.8, 7.1, 2.7, 11.1, 9.7, 3.0, 8…\n$ somehs                      <dbl> 15.8, 13.3, 11.6, 17.1, 6.6, 11.6, 21.6, 1…\n$ hs                          <dbl> 30.6, 27.8, 29.8, 37.2, 30.7, 46.0, 39.3, …\n$ somecollege                 <dbl> 20.9, 29.2, 21.4, 23.5, 25.7, 17.2, 21.6, …\n$ associate                   <dbl> 7.6, 10.1, 7.9, 7.3, 8.0, 4.1, 5.2, 6.6, 4…\n$ bachelor                    <dbl> 12.7, 10.0, 13.7, 5.9, 17.6, 7.1, 2.2, 7.8…\n$ grad                        <dbl> 5.1, 5.4, 9.8, 2.0, 8.7, 2.9, 0.4, 4.2, 3.…\n$ pov                         <dbl> 19.0, 8.8, 15.6, 25.5, 7.3, 8.1, 13.3, 23.…\n$ hs_orless                   <dbl> 53.7, 45.4, 47.2, 61.4, 40.0, 68.7, 70.6, …\n$ urc2006                     <dbl> 4, 4, 4, 1, 1, 1, 2, 3, 3, 3, 2, 5, 4, 1, …\n$ aod                         <dbl> 36.000000, 43.416667, 33.000000, 39.583333…\n$ state_California            <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ city_Not.in.a.city          <dbl> NA, NA, NA, 0, 1, 1, 1, NA, NA, NA, 0, NA,…\n```\n\n\n:::\n:::\n\n\n. . .\n\nHmm....lots of NAs now in `city_Not.in.a.city`\n\nLikely b/c there are cities in our testing dataset that were not in our training dataset...\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntraincities <- train_pm |> distinct(city)\ntestcities <- test_pm |> distinct(city)\n\n#get the number of cities that were different\ndim(dplyr::setdiff(traincities, testcities))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 381   1\n```\n\n\n:::\n\n```{.r .cell-code}\n#get the number of cities that overlapped\ndim(dplyr::intersect(traincities, testcities))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 55  1\n```\n\n\n:::\n:::\n\n\n## Aside: return to wrangling\n\nA quick return to wrangling...and re-splitting our data\n\n\n::: {.cell}\n\n```{.r .cell-code}\npm <- pm |>\n  mutate(city = case_when(city == \"Not in a city\" ~ \"Not in a city\",\n                          city != \"Not in a city\" ~ \"In a city\"))\n\nset.seed(1234) # same seed as before\npm_split <- rsample::initial_split(data = pm, prop = 2/3)\npm_split\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<Training/Testing/Total>\n<584/292/876>\n```\n\n\n:::\n\n```{.r .cell-code}\n train_pm <- rsample::training(pm_split)\n test_pm <- rsample::testing(pm_split)\n```\n:::\n\n\n. . .\n\nAnd a recipe update...(putting it all together)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnovel_rec <- recipe(train_pm) |>\n    update_role(everything(), new_role = \"predictor\") |>\n    update_role(value, new_role = \"outcome\") |>\n    update_role(id, new_role = \"id variable\") |>\n    update_role(\"fips\", new_role = \"county id\") |>\n    step_dummy(state, county, city, zcta, one_hot = TRUE) |>\n    step_corr(all_numeric()) |>\n    step_nzv(all_numeric()) \n```\n:::\n\n\n. . .\n\nre-`bake()`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprepped_rec <- prep(novel_rec, verbose = TRUE, retain = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\noper 1 step dummy [training] \noper 2 step corr [training] \noper 3 step nzv [training] \nThe retained training set is ~ 0.27 Mb  in memory.\n```\n\n\n:::\n\n```{.r .cell-code}\nbaked_train <- bake(prepped_rec, new_data = NULL)\n```\n:::\n\n\n. . .\n\nLooking at the output\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(baked_train)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 584\nColumns: 38\n$ id                          <fct> 18003.0004, 55041.0007, 6065.1003, 39009.0…\n$ value                       <dbl> 11.699065, 6.956780, 13.289744, 10.742000,…\n$ fips                        <fct> 18003, 55041, 6065, 39009, 39061, 24510, 6…\n$ lat                         <dbl> 41.09497, 45.56300, 33.94603, 39.44217, 39…\n$ lon                         <dbl> -85.10182, -88.80880, -117.40063, -81.9088…\n$ CMAQ                        <dbl> 10.383231, 3.411247, 11.404085, 7.971165, …\n$ zcta_area                   <dbl> 16696709, 370280916, 41957182, 132383592, …\n$ zcta_pop                    <dbl> 21306, 4141, 44001, 1115, 6566, 934, 41192…\n$ imp_a500                    <dbl> 28.9783737, 0.0000000, 30.3901384, 0.00000…\n$ imp_a15000                  <dbl> 13.0547959, 0.3676404, 23.7457506, 0.33079…\n$ county_area                 <dbl> 1702419942, 2626421270, 18664696661, 13043…\n$ county_pop                  <dbl> 355329, 9304, 2189641, 64757, 802374, 6209…\n$ log_dist_to_prisec          <dbl> 6.621891, 8.415468, 7.419762, 6.344681, 5.…\n$ log_pri_length_5000         <dbl> 8.517193, 8.517193, 10.150514, 8.517193, 9…\n$ log_pri_length_25000        <dbl> 12.77378, 10.16440, 13.14450, 10.12663, 13…\n$ log_prisec_length_500       <dbl> 6.214608, 6.214608, 6.214608, 6.214608, 7.…\n$ log_prisec_length_1000      <dbl> 9.240294, 7.600902, 7.600902, 8.793450, 8.…\n$ log_prisec_length_5000      <dbl> 11.485093, 9.425537, 10.155961, 10.562382,…\n$ log_prisec_length_10000     <dbl> 12.75582, 11.44833, 11.59563, 11.69093, 12…\n$ log_prisec_length_25000     <dbl> 13.98749, 13.15082, 13.44293, 13.58697, 14…\n$ log_nei_2008_pm10_sum_10000 <dbl> 4.91110140, 3.86982666, 4.03184660, 0.0000…\n$ log_nei_2008_pm10_sum_15000 <dbl> 5.399131, 3.883689, 5.459257, 0.000000, 6.…\n$ log_nei_2008_pm10_sum_25000 <dbl> 5.816047, 3.887264, 6.884537, 3.765635, 6.…\n$ popdens_county              <dbl> 208.719947, 3.542463, 117.314577, 49.64834…\n$ popdens_zcta                <dbl> 1276.059851, 11.183401, 1048.711994, 8.422…\n$ nohs                        <dbl> 4.3, 5.1, 3.7, 4.8, 2.1, 0.0, 2.5, 7.7, 0.…\n$ somehs                      <dbl> 6.7, 10.4, 5.9, 11.5, 10.5, 0.0, 4.3, 7.5,…\n$ hs                          <dbl> 31.7, 40.3, 17.9, 47.3, 30.0, 0.0, 17.8, 2…\n$ somecollege                 <dbl> 27.2, 24.1, 26.3, 20.0, 27.1, 0.0, 26.1, 2…\n$ associate                   <dbl> 8.2, 7.4, 8.3, 3.1, 8.5, 71.4, 13.2, 7.6, …\n$ bachelor                    <dbl> 15.0, 8.6, 20.2, 9.8, 14.2, 0.0, 23.4, 17.…\n$ grad                        <dbl> 6.8, 4.2, 17.7, 3.5, 7.6, 28.6, 12.6, 12.3…\n$ pov                         <dbl> 13.500, 18.900, 6.700, 14.400, 12.500, 3.5…\n$ hs_orless                   <dbl> 42.7, 55.8, 27.5, 63.6, 42.6, 0.0, 24.6, 3…\n$ urc2006                     <dbl> 3, 6, 1, 5, 1, 1, 2, 1, 2, 6, 4, 4, 4, 4, …\n$ aod                         <dbl> 54.11111, 31.16667, 83.12500, 33.36364, 50…\n$ state_California            <dbl> 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, …\n$ city_Not.in.a.city          <dbl> 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, …\n```\n\n\n:::\n:::\n\n\n. . .\n\nMaking sure the NA issue is taken are of:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbaked_test_pm <- bake(prepped_rec, new_data = test_pm)\n\nglimpse(baked_test_pm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 292\nColumns: 38\n$ id                          <fct> 1033.1002, 1055.001, 1069.0003, 1073.0023,…\n$ value                       <dbl> 11.212174, 12.375394, 10.508850, 15.591017…\n$ fips                        <fct> 1033, 1055, 1069, 1073, 1073, 1073, 1073, …\n$ lat                         <dbl> 34.75878, 33.99375, 31.22636, 33.55306, 33…\n$ lon                         <dbl> -87.65056, -85.99107, -85.39077, -86.81500…\n$ CMAQ                        <dbl> 9.402679, 9.241744, 9.121892, 10.235612, 1…\n$ zcta_area                   <dbl> 16716984, 154069359, 162685124, 26929603, …\n$ zcta_pop                    <dbl> 9042, 20045, 30217, 9010, 16140, 3699, 137…\n$ imp_a500                    <dbl> 19.17301038, 16.49307958, 19.13927336, 41.…\n$ imp_a15000                  <dbl> 5.2472094, 5.1612102, 4.7401296, 17.452484…\n$ county_area                 <dbl> 1534877333, 1385618994, 1501737720, 287819…\n$ county_pop                  <dbl> 54428, 104430, 101547, 658466, 658466, 194…\n$ log_dist_to_prisec          <dbl> 5.760131, 5.261457, 7.112373, 6.600958, 6.…\n$ log_pri_length_5000         <dbl> 8.517193, 9.066563, 8.517193, 11.156977, 1…\n$ log_pri_length_25000        <dbl> 10.15769, 12.01356, 10.12663, 12.98762, 12…\n$ log_prisec_length_500       <dbl> 8.611945, 8.740680, 6.214608, 6.214608, 6.…\n$ log_prisec_length_1000      <dbl> 9.735569, 9.627898, 7.600902, 9.075921, 8.…\n$ log_prisec_length_5000      <dbl> 11.770407, 11.728889, 12.298627, 12.281645…\n$ log_prisec_length_10000     <dbl> 12.840663, 12.768279, 12.994141, 13.278416…\n$ log_prisec_length_25000     <dbl> 13.79973, 13.70026, 13.85550, 14.45221, 13…\n$ log_nei_2008_pm10_sum_10000 <dbl> 6.69187313, 4.43719884, 0.92888890, 8.2097…\n$ log_nei_2008_pm10_sum_15000 <dbl> 6.70127741, 4.46267932, 3.67473904, 8.6488…\n$ log_nei_2008_pm10_sum_25000 <dbl> 7.148858, 4.678311, 3.744629, 8.858019, 8.…\n$ popdens_county              <dbl> 35.460814, 75.367038, 67.619664, 228.77763…\n$ popdens_zcta                <dbl> 540.8870404, 130.1037411, 185.7391706, 334…\n$ nohs                        <dbl> 7.3, 4.3, 5.8, 7.1, 2.7, 11.1, 9.7, 3.0, 8…\n$ somehs                      <dbl> 15.8, 13.3, 11.6, 17.1, 6.6, 11.6, 21.6, 1…\n$ hs                          <dbl> 30.6, 27.8, 29.8, 37.2, 30.7, 46.0, 39.3, …\n$ somecollege                 <dbl> 20.9, 29.2, 21.4, 23.5, 25.7, 17.2, 21.6, …\n$ associate                   <dbl> 7.6, 10.1, 7.9, 7.3, 8.0, 4.1, 5.2, 6.6, 4…\n$ bachelor                    <dbl> 12.7, 10.0, 13.7, 5.9, 17.6, 7.1, 2.2, 7.8…\n$ grad                        <dbl> 5.1, 5.4, 9.8, 2.0, 8.7, 2.9, 0.4, 4.2, 3.…\n$ pov                         <dbl> 19.0, 8.8, 15.6, 25.5, 7.3, 8.1, 13.3, 23.…\n$ hs_orless                   <dbl> 53.7, 45.4, 47.2, 61.4, 40.0, 68.7, 70.6, …\n$ urc2006                     <dbl> 4, 4, 4, 1, 1, 1, 2, 3, 3, 3, 2, 5, 4, 1, …\n$ aod                         <dbl> 36.000000, 43.416667, 33.000000, 39.583333…\n$ state_California            <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ city_Not.in.a.city          <dbl> 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, …\n```\n\n\n:::\n:::\n\n\n## Specifying our model (`parsnip`) {.smaller}\n\nThere are four things we need to define about our model:\n\n::: incremental\n1.  The **type** of model (using specific functions in parsnip like `rand_forest()`, `logistic_reg()` etc.)\\\n2.  The package or **engine** that we will use to implement the type of model selected (using the `set_engine()` function)\n3.  The **mode** of learning - classification or regression (using the `set_mode()` function)\n4.  Any **arguments** necessary for the model/package selected (using the `set_args()`function - for example the `mtry =` argument for random forest which is the number of variables to be used as options for splitting at each tree node)\n:::\n\n## Step 1: Specify the model\n\n-   We'll start with linear regression, but move to random forest\n-   See [here](https://www.tidymodels.org/find/parsnip/){target=\"_blank\"} for modeling options in `parsnip`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm_PM_model <- parsnip::linear_reg() |>\n  parsnip::set_engine(\"lm\") |>\n  set_mode(\"regression\")\n\nlm_PM_model\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n```\n\n\n:::\n:::\n\n\n## Step 2: Fit the model\n\n-   `workflows` package allows us to keep track of both our pre-processing steps and our model specification\n-   It also allows us to implement fancier optimizations in an automated way and it can also handle post-processing operations.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nPM_wflow <- workflows::workflow() |>\n            workflows::add_recipe(novel_rec) |>\n            workflows::add_model(lm_PM_model)\nPM_wflow\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_dummy()\n• step_corr()\n• step_nzv()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n```\n\n\n:::\n:::\n\n\n[❓ Who can explain the difference between a recipe, baking, and a workflow?]{style=\"background-color: #ADD8E6\"}\n\n## Step 3: Prepare the recipe (estimate the parameters)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nPM_wflow_fit <- parsnip::fit(PM_wflow, data = train_pm)\nPM_wflow_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_dummy()\n• step_corr()\n• step_nzv()\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:\nstats::lm(formula = ..y ~ ., data = data)\n\nCoefficients:\n                (Intercept)                          lat  \n                  2.936e+02                    3.261e-02  \n                        lon                         CMAQ  \n                  1.586e-02                    2.463e-01  \n                  zcta_area                     zcta_pop  \n                 -3.433e-10                    1.013e-05  \n                   imp_a500                   imp_a15000  \n                  5.064e-03                   -3.066e-03  \n                county_area                   county_pop  \n                 -2.324e-11                   -7.576e-08  \n         log_dist_to_prisec          log_pri_length_5000  \n                  6.214e-02                   -2.006e-01  \n       log_pri_length_25000        log_prisec_length_500  \n                 -5.411e-02                    2.204e-01  \n     log_prisec_length_1000       log_prisec_length_5000  \n                  1.154e-01                    2.374e-01  \n    log_prisec_length_10000      log_prisec_length_25000  \n                 -3.436e-02                    5.224e-01  \nlog_nei_2008_pm10_sum_10000  log_nei_2008_pm10_sum_15000  \n                  1.829e-01                   -2.355e-02  \nlog_nei_2008_pm10_sum_25000               popdens_county  \n                  2.403e-02                    2.203e-05  \n               popdens_zcta                         nohs  \n                 -2.132e-06                   -2.983e+00  \n                     somehs                           hs  \n                 -2.956e+00                   -2.962e+00  \n                somecollege                    associate  \n                 -2.967e+00                   -2.999e+00  \n                   bachelor                         grad  \n                 -2.979e+00                   -2.978e+00  \n                        pov                    hs_orless  \n                  1.859e-03                           NA  \n                    urc2006                          aod  \n                  2.577e-01                    1.535e-02  \n           state_California           city_Not.in.a.city  \n                  3.114e+00                   -4.250e-02  \n```\n\n\n:::\n:::\n\n\n## Step 4: Assess model fit\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwflowoutput <- PM_wflow_fit |> \n  extract_fit_parsnip() |> \n  broom::tidy() \n\nwflowoutput\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 36 × 5\n   term         estimate std.error statistic       p.value\n   <chr>           <dbl>     <dbl>     <dbl>         <dbl>\n 1 (Intercept)  2.94e+ 2  1.18e+ 2     2.49  0.0130       \n 2 lat          3.26e- 2  2.28e- 2     1.43  0.153        \n 3 lon          1.59e- 2  1.01e- 2     1.58  0.115        \n 4 CMAQ         2.46e- 1  3.97e- 2     6.20  0.00000000108\n 5 zcta_area   -3.43e-10  1.60e-10    -2.15  0.0320       \n 6 zcta_pop     1.01e- 5  5.33e- 6     1.90  0.0578       \n 7 imp_a500     5.06e- 3  7.42e- 3     0.683 0.495        \n 8 imp_a15000  -3.07e- 3  1.16e- 2    -0.263 0.792        \n 9 county_area -2.32e-11  1.97e-11    -1.18  0.238        \n10 county_pop  -7.58e- 8  9.29e- 8    -0.815 0.415        \n# ℹ 26 more rows\n```\n\n\n:::\n:::\n\n\n-   We have fit our model on our training data\n-   We have created a model to predict values of air pollution based on the predictors that we have included\n\n. . .\n\nUnderstanding what variables are most important in our model...\n\n\n::: {.cell}\n\n```{.r .cell-code}\nPM_wflow_fit |> \n  extract_fit_parsnip() |> \n  vip::vip(num_features = 10)\n```\n\n::: {.cell-output-display}\n![](13-cs02-analysis_files/figure-html/unnamed-chunk-26-1.png){width=2100}\n:::\n:::\n\n\n. . .\n\nA closer look at monitors in CA:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbaked_train |> \n  mutate(state_California = as.factor(state_California)) |>\n  mutate(state_California = recode(state_California, \n                                   \"0\" = \"Not California\", \n                                   \"1\" = \"California\")) |>\n  ggplot(aes(x = state_California, y = value)) + \n  geom_boxplot() +\n  geom_jitter(width = .05) + \n  xlab(\"Location of Monitor\")\n```\n\n::: {.cell-output-display}\n![](13-cs02-analysis_files/figure-html/unnamed-chunk-27-1.png){width=2100}\n:::\n:::\n\n\n. . .\n\nRemember: machine learning (ML) as an optimization problem that tries to minimize the distance between our predicted outcome $\\hat{Y} = f(X)$ and actual outcome $Y$ using our features (or predictor variables) $X$ as input to a function $f$ that we want to estimate.\n\n$$d(Y - \\hat{Y})$$\n\n. . .\n\nLet's pull out our predicted outcome values $\\hat{Y} = f(X)$ from the models we fit (using different approaches).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwf_fit <- PM_wflow_fit |> \n  extract_fit_parsnip()\n\nwf_fitted_values <- \n  broom::augment(wf_fit[[\"fit\"]], data = baked_train) |> \n  select(value, .fitted:.std.resid)\n\nhead(wf_fitted_values)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 6\n  value .fitted   .hat .sigma   .cooksd .std.resid\n  <dbl>   <dbl>  <dbl>  <dbl>     <dbl>      <dbl>\n1 11.7    12.2  0.0370   2.05 0.0000648     -0.243\n2  6.96    9.14 0.0496   2.05 0.00179       -1.09 \n3 13.3    12.6  0.0484   2.05 0.000151       0.322\n4 10.7    10.4  0.0502   2.05 0.0000504      0.183\n5 14.5    11.9  0.0243   2.05 0.00113        1.26 \n6 12.2     9.52 0.476    2.04 0.0850         1.81 \n```\n\n\n:::\n:::\n\n\n## Visualizing Model Performance\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwf_fitted_values |> \n  ggplot(aes(x =  value, y = .fitted)) + \n  geom_point() + \n  xlab(\"actual outcome values\") + \n  ylab(\"predicted outcome values\")\n```\n\n::: {.cell-output-display}\n![](13-cs02-analysis_files/figure-html/unnamed-chunk-29-1.png){width=2100}\n:::\n:::\n\n\n[❓ What do you notice about/learn from these results?]{style=\"background-color: #ADD8E6\"}\n\n## Quantifying Model Performance {.smaller}\n\n$$RMSE = \\sqrt{\\frac{\\sum_{i=1}^{n}{(\\hat{y_t}- y_t)}^2}{n}}$$\n\n. . .\n\nCan use the `yardstick` package using the `rmse`()\\` function to calculate:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nyardstick::metrics(wf_fitted_values,\n                   truth = value, estimate = .fitted)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard       1.98 \n2 rsq     standard       0.392\n3 mae     standard       1.47 \n```\n\n\n:::\n:::\n\n\n-   RMSE isn't too bad\n-   $R^2$ suggests model is only explaining 39% of the variance in the data\n-   The MAE value suggests that the average difference between the value predicted and the real value was 1.47 ug/m3. The range of the values was 3-22 in the training data, so this is a relatively small amount\n\n## Cross-Validation\n\nResampling + Re-partitioning:\n\n<p align=\"center\">\n\n<img src=\"images/17/resampling.png\" width=\"550\"/>\n\n</p>\n\n. . .\n\nPreparing the data for cross-validation:\n\n<p align=\"center\">\n\n<img src=\"images/17/vfold.png\" width=\"550\"/>\n\n</p>\n\nNote: this is called v-fold or k-fold CV\n\n## Implementing in `rsample()`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\nvfold_pm <- rsample::vfold_cv(data = train_pm, v = 4)\nvfold_pm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#  4-fold cross-validation \n# A tibble: 4 × 2\n  splits            id   \n  <list>            <chr>\n1 <split [438/146]> Fold1\n2 <split [438/146]> Fold2\n3 <split [438/146]> Fold3\n4 <split [438/146]> Fold4\n```\n\n\n:::\n:::\n\n\n. . .\n\n\n::: {.cell}\n\n```{.r .cell-code}\npull(vfold_pm, splits)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[[1]]\n<Analysis/Assess/Total>\n<438/146/584>\n\n[[2]]\n<Analysis/Assess/Total>\n<438/146/584>\n\n[[3]]\n<Analysis/Assess/Total>\n<438/146/584>\n\n[[4]]\n<Analysis/Assess/Total>\n<438/146/584>\n```\n\n\n:::\n:::\n\n\n. . .\n\nVisualizing this process:\n\n<p align=\"center\">\n\n<img src=\"images/17/cross_validation.png\" width=\"550\"/>\n\n</p>\n\n## Model Assessment on v-folds\n\nWhere this workflow thing really shines...\n\n\n::: {.cell wanring='false'}\n\n```{.r .cell-code}\nresample_fit <- tune::fit_resamples(PM_wflow, vfold_pm)\n```\n:::\n\n\n. . .\n\nGives us a sense of the RMSE across the four folds:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntune::show_best(resample_fit, metric = \"rmse\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 6\n  .metric .estimator  mean     n std_err .config             \n  <chr>   <chr>      <dbl> <int>   <dbl> <chr>               \n1 rmse    standard    2.12     4  0.0444 Preprocessor1_Model1\n```\n\n\n:::\n:::\n\n\n# A different model? {background-color=\"#92A86A\"}\n\n## Random Forest\n\nFitting a different model...is based on a decision tree:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](https://miro.medium.com/max/1000/1*LMoJmXCsQlciGTEyoSN39g.jpeg)\n:::\n:::\n\n\n##### [\\[source\\]](https://towardsdatascience.com/understanding-random-forest-58381e0602d2){target=\"_blank\"}\n\n## But not just one tree...\n\nBut...in the case of [random forest](https://towardsdatascience.com/decision-tree-ensembles-bagging-and-boosting-266a8ba60fd9){target=\"_blank\"}:\n\n::: incremental\n-   multiple decision trees are created (hence: forest),\n-   each tree is built using a random subset of the training data (with replacement) (hence: random)\n-   helps to keep the algorithm from overfitting the data\n-   The mean of the predictions from each of the trees is used in the final output.\n:::\n\n## Visualizing a RF\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](https://miro.medium.com/max/1400/0*f_qQPFpdofWGLQqc.png)\n:::\n:::\n\n\n## Updating our `recipe()`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nRF_rec <- recipe(train_pm) |>\n    update_role(everything(), new_role = \"predictor\")|>\n    update_role(value, new_role = \"outcome\")|>\n    update_role(id, new_role = \"id variable\") |>\n    update_role(\"fips\", new_role = \"county id\") |>\n    step_novel(\"state\") |>\n    step_string2factor(\"state\", \"county\", \"city\") |>\n    step_rm(\"county\") |>\n    step_rm(\"zcta\") |>\n    step_corr(all_numeric())|>\n    step_nzv(all_numeric())\n```\n:::\n\n\n-   can use our categorical data as is (no dummy coding)\n-   `step_novel()`necessary here for the `state` variable to get all cross validation folds to work, (b/c there will be different levels included in each fold test and training sets. The new levels for some of the test sets would otherwise result in an error.; \"step_novel creates a specification of a recipe step that will assign a previously unseen factor level to a new value.\"\n\n## Model Specification\n\nModel parameters:\n\n1.  `mtry` - The number of predictor variables (or features) that will be randomly sampled at each split when creating the tree models. The default number for regression analyses is the number of predictors divided by 3.\n2.  `min_n` - The minimum number of data points in a node that are required for the node to be split further.\n3.  `trees` - the number of trees in the ensemble\n\n. . .\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# install.packages(\"randomForest\")\nRF_PM_model <- parsnip::rand_forest(mtry = 10, min_n = 3) |> \n  set_engine(\"randomForest\") |>\n  set_mode(\"regression\")\n\nRF_PM_model\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRandom Forest Model Specification (regression)\n\nMain Arguments:\n  mtry = 10\n  min_n = 3\n\nComputational engine: randomForest \n```\n\n\n:::\n:::\n\n\n## Workflow\n\n\n::: {.cell}\n\n```{.r .cell-code}\nRF_wflow <- workflows::workflow() |>\n  workflows::add_recipe(RF_rec) |>\n  workflows::add_model(RF_PM_model)\n\nRF_wflow\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n6 Recipe Steps\n\n• step_novel()\n• step_string2factor()\n• step_rm()\n• step_rm()\n• step_corr()\n• step_nzv()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRandom Forest Model Specification (regression)\n\nMain Arguments:\n  mtry = 10\n  min_n = 3\n\nComputational engine: randomForest \n```\n\n\n:::\n:::\n\n\n## Fit the Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nRF_wflow_fit <- parsnip::fit(RF_wflow, data = train_pm)\n\nRF_wflow_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n6 Recipe Steps\n\n• step_novel()\n• step_string2factor()\n• step_rm()\n• step_rm()\n• step_corr()\n• step_nzv()\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:\n randomForest(x = maybe_data_frame(x), y = y, mtry = min_cols(~10,      x), nodesize = min_rows(~3, x)) \n               Type of random forest: regression\n                     Number of trees: 500\nNo. of variables tried at each split: 10\n\n          Mean of squared residuals: 2.633639\n                    % Var explained: 59.29\n```\n\n\n:::\n:::\n\n\n## Assess Feature Importance\n\n\n::: {.cell}\n\n```{.r .cell-code}\nRF_wflow_fit |> \n  extract_fit_parsnip() |> \n  vip::vip(num_features = 10)\n```\n\n::: {.cell-output-display}\n![](13-cs02-analysis_files/figure-html/unnamed-chunk-41-1.png){width=2100}\n:::\n:::\n\n\n[❓ What's your interpretation of these results?]{style=\"background-color: #ADD8E6\"}\n\n## Assess Model Performance\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(456)\nresample_RF_fit <- tune::fit_resamples(RF_wflow, vfold_pm)\ncollect_metrics(resample_RF_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 6\n  .metric .estimator  mean     n std_err .config             \n  <chr>   <chr>      <dbl> <int>   <dbl> <chr>               \n1 rmse    standard   1.67      4  0.101  Preprocessor1_Model1\n2 rsq     standard   0.591     4  0.0514 Preprocessor1_Model1\n```\n\n\n:::\n:::\n\n\n. . .\n\nFor comparison:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncollect_metrics(resample_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 6\n  .metric .estimator  mean     n std_err .config             \n  <chr>   <chr>      <dbl> <int>   <dbl> <chr>               \n1 rmse    standard   2.12      4  0.0444 Preprocessor1_Model1\n2 rsq     standard   0.307     4  0.0263 Preprocessor1_Model1\n```\n\n\n:::\n:::\n\n\n[❓ Thoughts on which model better achieves our goal?]{style=\"background-color: #ADD8E6\"}\n\n## Model Tuning\n\n[Hyperparameters](https://machinelearningmastery.com/difference-between-a-parameter-and-a-hyperparameter/) are often things that we need to specify about a model. Instead of arbitrarily specifying this, we can try to determine the best option for model performance by a process called tuning.\n\n. . .\n\nRather than specifying values, we can use `tune()`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntune_RF_model <- rand_forest(mtry = tune(), min_n = tune()) |>\n  set_engine(\"randomForest\") |>\n  set_mode(\"regression\")\n    \ntune_RF_model\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRandom Forest Model Specification (regression)\n\nMain Arguments:\n  mtry = tune()\n  min_n = tune()\n\nComputational engine: randomForest \n```\n\n\n:::\n:::\n\n\n. . .\n\nCreate Workflow:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nRF_tune_wflow <- workflows::workflow() |>\n  workflows::add_recipe(RF_rec) |>\n  workflows::add_model(tune_RF_model)\n\nRF_tune_wflow\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n6 Recipe Steps\n\n• step_novel()\n• step_string2factor()\n• step_rm()\n• step_rm()\n• step_corr()\n• step_nzv()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRandom Forest Model Specification (regression)\n\nMain Arguments:\n  mtry = tune()\n  min_n = tune()\n\nComputational engine: randomForest \n```\n\n\n:::\n:::\n\n\nDetect how many cores you have access to:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_cores <- parallel::detectCores()\nn_cores\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 10\n```\n\n\n:::\n:::\n\n\n. . .\n\nThis code will take some time to run:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# install.packages(\"doParallel\")\ndoParallel::registerDoParallel(cores = n_cores)\n\nset.seed(123)\ntune_RF_results <- tune_grid(object = RF_tune_wflow, resamples = vfold_pm, grid = 20)\ntune_RF_results\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Tuning results\n# 4-fold cross-validation \n# A tibble: 4 × 4\n  splits            id    .metrics          .notes          \n  <list>            <chr> <list>            <list>          \n1 <split [438/146]> Fold1 <tibble [40 × 6]> <tibble [0 × 3]>\n2 <split [438/146]> Fold2 <tibble [40 × 6]> <tibble [0 × 3]>\n3 <split [438/146]> Fold3 <tibble [40 × 6]> <tibble [1 × 3]>\n4 <split [438/146]> Fold4 <tibble [40 × 6]> <tibble [0 × 3]>\n\nThere were issues with some computations:\n\n  - Warning(s) x1: 36 columns were requested but there were 35 predictors in the dat...\n\nRun `show_notes(.Last.tune.result)` for more information.\n```\n\n\n:::\n:::\n\n\n## Check Metrics:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntune_RF_results |>\n  collect_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 40 × 8\n    mtry min_n .metric .estimator  mean     n std_err .config              \n   <int> <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n 1    12    33 rmse    standard   1.72      4  0.0866 Preprocessor1_Model01\n 2    12    33 rsq     standard   0.562     4  0.0466 Preprocessor1_Model01\n 3    27    35 rmse    standard   1.69      4  0.102  Preprocessor1_Model02\n 4    27    35 rsq     standard   0.563     4  0.0511 Preprocessor1_Model02\n 5    22    40 rmse    standard   1.71      4  0.106  Preprocessor1_Model03\n 6    22    40 rsq     standard   0.556     4  0.0543 Preprocessor1_Model03\n 7     1    27 rmse    standard   2.03      4  0.0501 Preprocessor1_Model04\n 8     1    27 rsq     standard   0.440     4  0.0245 Preprocessor1_Model04\n 9     6    32 rmse    standard   1.77      4  0.0756 Preprocessor1_Model05\n10     6    32 rsq     standard   0.552     4  0.0435 Preprocessor1_Model05\n# ℹ 30 more rows\n```\n\n\n:::\n:::\n\n\n. . .\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshow_best(tune_RF_results, metric = \"rmse\", n = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 8\n   mtry min_n .metric .estimator  mean     n std_err .config              \n  <int> <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1    32    11 rmse    standard    1.65     4   0.113 Preprocessor1_Model10\n```\n\n\n:::\n:::\n\n\n## Final Model Evaluation\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntuned_RF_values<- select_best(tune_RF_results, \"rmse\")\ntuned_RF_values\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 3\n   mtry min_n .config              \n  <int> <int> <chr>                \n1    32    11 Preprocessor1_Model10\n```\n\n\n:::\n:::\n\n\n. . .\n\nThe testing data!\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# specify best combination from tune in workflow\nRF_tuned_wflow <-RF_tune_wflow |>\n  tune::finalize_workflow(tuned_RF_values)\n\n# fit model with those parameters on train AND test\noverallfit <- RF_wflow |>\n  tune::last_fit(pm_split)\n\ncollect_metrics(overallfit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  <chr>   <chr>          <dbl> <chr>               \n1 rmse    standard       1.72  Preprocessor1_Model1\n2 rsq     standard       0.608 Preprocessor1_Model1\n```\n\n\n:::\n:::\n\n\nResults are similar to what we saw in training (RMSE: 1.65)\n\n. . .\n\nGetting the predictions for the test data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_predictions <- collect_predictions(overallfit)\n```\n:::\n\n\n# Visualizing our results {background-color=\"#92A86A\"}\n\n## A map of the US {.smaller}\n\nPackages needed:\n\n1.  `sf` - the simple features package helps to convert geographical coordinates into `geometry` variables which are useful for making 2D plots\n2.  `maps` - this package contains geographical outlines and plotting functions to create plots with maps\n3.  `rnaturalearth`- this allows for easy interaction with map data from [Natural Earth](http://www.naturalearthdata.com/) which is a public domain map dataset\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sf)\nlibrary(maps)\nlibrary(rnaturalearth)\n```\n:::\n\n\n## Outline of the US\n\n\n::: {.cell}\n\n```{.r .cell-code}\nworld <- ne_countries(scale = \"medium\", returnclass = \"sf\")\nglimpse(world)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 241\nColumns: 64\n$ scalerank  <int> 3, 1, 1, 1, 1, 3, 3, 1, 1, 1, 3, 1, 5, 3, 1, 1, 1, 1, 1, 1,…\n$ featurecla <chr> \"Admin-0 country\", \"Admin-0 country\", \"Admin-0 country\", \"A…\n$ labelrank  <dbl> 5, 3, 3, 6, 6, 6, 6, 4, 2, 6, 4, 4, 5, 6, 6, 2, 4, 5, 6, 2,…\n$ sovereignt <chr> \"Netherlands\", \"Afghanistan\", \"Angola\", \"United Kingdom\", \"…\n$ sov_a3     <chr> \"NL1\", \"AFG\", \"AGO\", \"GB1\", \"ALB\", \"FI1\", \"AND\", \"ARE\", \"AR…\n$ adm0_dif   <dbl> 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,…\n$ level      <dbl> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,…\n$ type       <chr> \"Country\", \"Sovereign country\", \"Sovereign country\", \"Depen…\n$ admin      <chr> \"Aruba\", \"Afghanistan\", \"Angola\", \"Anguilla\", \"Albania\", \"A…\n$ adm0_a3    <chr> \"ABW\", \"AFG\", \"AGO\", \"AIA\", \"ALB\", \"ALD\", \"AND\", \"ARE\", \"AR…\n$ geou_dif   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ geounit    <chr> \"Aruba\", \"Afghanistan\", \"Angola\", \"Anguilla\", \"Albania\", \"A…\n$ gu_a3      <chr> \"ABW\", \"AFG\", \"AGO\", \"AIA\", \"ALB\", \"ALD\", \"AND\", \"ARE\", \"AR…\n$ su_dif     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ subunit    <chr> \"Aruba\", \"Afghanistan\", \"Angola\", \"Anguilla\", \"Albania\", \"A…\n$ su_a3      <chr> \"ABW\", \"AFG\", \"AGO\", \"AIA\", \"ALB\", \"ALD\", \"AND\", \"ARE\", \"AR…\n$ brk_diff   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ name       <chr> \"Aruba\", \"Afghanistan\", \"Angola\", \"Anguilla\", \"Albania\", \"A…\n$ name_long  <chr> \"Aruba\", \"Afghanistan\", \"Angola\", \"Anguilla\", \"Albania\", \"A…\n$ brk_a3     <chr> \"ABW\", \"AFG\", \"AGO\", \"AIA\", \"ALB\", \"ALD\", \"AND\", \"ARE\", \"AR…\n$ brk_name   <chr> \"Aruba\", \"Afghanistan\", \"Angola\", \"Anguilla\", \"Albania\", \"A…\n$ brk_group  <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ abbrev     <chr> \"Aruba\", \"Afg.\", \"Ang.\", \"Ang.\", \"Alb.\", \"Aland\", \"And.\", \"…\n$ postal     <chr> \"AW\", \"AF\", \"AO\", \"AI\", \"AL\", \"AI\", \"AND\", \"AE\", \"AR\", \"ARM…\n$ formal_en  <chr> \"Aruba\", \"Islamic State of Afghanistan\", \"People's Republic…\n$ formal_fr  <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ note_adm0  <chr> \"Neth.\", NA, NA, \"U.K.\", NA, \"Fin.\", NA, NA, NA, NA, \"U.S.A…\n$ note_brk   <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"Multiple claim…\n$ name_sort  <chr> \"Aruba\", \"Afghanistan\", \"Angola\", \"Anguilla\", \"Albania\", \"A…\n$ name_alt   <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ mapcolor7  <dbl> 4, 5, 3, 6, 1, 4, 1, 2, 3, 3, 4, 4, 1, 7, 2, 1, 3, 1, 2, 3,…\n$ mapcolor8  <dbl> 2, 6, 2, 6, 4, 1, 4, 1, 1, 1, 5, 5, 2, 5, 2, 2, 1, 6, 2, 2,…\n$ mapcolor9  <dbl> 2, 8, 6, 6, 1, 4, 1, 3, 3, 2, 1, 1, 2, 9, 5, 2, 3, 5, 5, 1,…\n$ mapcolor13 <dbl> 9, 7, 1, 3, 6, 6, 8, 3, 13, 10, 1, NA, 7, 11, 5, 7, 4, 8, 8…\n$ pop_est    <dbl> 103065, 28400000, 12799293, 14436, 3639453, 27153, 83888, 4…\n$ gdp_md_est <dbl> 2258.0, 22270.0, 110300.0, 108.9, 21810.0, 1563.0, 3660.0, …\n$ pop_year   <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ lastcensus <dbl> 2010, 1979, 1970, NA, 2001, NA, 1989, 2010, 2010, 2001, 201…\n$ gdp_year   <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ economy    <chr> \"6. Developing region\", \"7. Least developed region\", \"7. Le…\n$ income_grp <chr> \"2. High income: nonOECD\", \"5. Low income\", \"3. Upper middl…\n$ wikipedia  <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ fips_10    <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ iso_a2     <chr> \"AW\", \"AF\", \"AO\", \"AI\", \"AL\", \"AX\", \"AD\", \"AE\", \"AR\", \"AM\",…\n$ iso_a3     <chr> \"ABW\", \"AFG\", \"AGO\", \"AIA\", \"ALB\", \"ALA\", \"AND\", \"ARE\", \"AR…\n$ iso_n3     <chr> \"533\", \"004\", \"024\", \"660\", \"008\", \"248\", \"020\", \"784\", \"03…\n$ un_a3      <chr> \"533\", \"004\", \"024\", \"660\", \"008\", \"248\", \"020\", \"784\", \"03…\n$ wb_a2      <chr> \"AW\", \"AF\", \"AO\", NA, \"AL\", NA, \"AD\", \"AE\", \"AR\", \"AM\", \"AS…\n$ wb_a3      <chr> \"ABW\", \"AFG\", \"AGO\", NA, \"ALB\", NA, \"ADO\", \"ARE\", \"ARG\", \"A…\n$ woe_id     <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ adm0_a3_is <chr> \"ABW\", \"AFG\", \"AGO\", \"AIA\", \"ALB\", \"ALA\", \"AND\", \"ARE\", \"AR…\n$ adm0_a3_us <chr> \"ABW\", \"AFG\", \"AGO\", \"AIA\", \"ALB\", \"ALD\", \"AND\", \"ARE\", \"AR…\n$ adm0_a3_un <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ adm0_a3_wb <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ continent  <chr> \"North America\", \"Asia\", \"Africa\", \"North America\", \"Europe…\n$ region_un  <chr> \"Americas\", \"Asia\", \"Africa\", \"Americas\", \"Europe\", \"Europe…\n$ subregion  <chr> \"Caribbean\", \"Southern Asia\", \"Middle Africa\", \"Caribbean\",…\n$ region_wb  <chr> \"Latin America & Caribbean\", \"South Asia\", \"Sub-Saharan Afr…\n$ name_len   <dbl> 5, 11, 6, 8, 7, 5, 7, 20, 9, 7, 14, 10, 23, 22, 17, 9, 7, 1…\n$ long_len   <dbl> 5, 11, 6, 8, 7, 13, 7, 20, 9, 7, 14, 10, 27, 35, 19, 9, 7, …\n$ abbrev_len <dbl> 5, 4, 4, 4, 4, 5, 4, 6, 4, 4, 9, 4, 7, 10, 6, 4, 5, 4, 4, 5…\n$ tiny       <dbl> 4, NA, NA, NA, NA, 5, 5, NA, NA, NA, 3, NA, NA, 2, 4, NA, N…\n$ homepart   <dbl> NA, 1, 1, NA, 1, NA, 1, 1, 1, 1, NA, 1, NA, NA, 1, 1, 1, 1,…\n$ geometry   <MULTIPOLYGON [°]> MULTIPOLYGON (((-69.89912 1..., MULTIPOLYGON (…\n```\n\n\n:::\n:::\n\n\n\n## World map:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = world) +\n    geom_sf() \n```\n\n::: {.cell-output-display}\n![](13-cs02-analysis_files/figure-html/unnamed-chunk-55-1.png){width=2100}\n:::\n:::\n\n\n## Just the US\n\nAccording to this [link](https://en.wikipedia.org/wiki/List_of_extreme_points_of_the_United_States#Westernmost){target=\"_blank\"}, these are the latitude and longitude bounds of the continental US:\n\n-   top = 49.3457868 \\# north lat\n-   left = -124.7844079 \\# west long\n-   right = -66.9513812 \\# east long\n-   bottom = 24.7433195 \\# south lat\n\n## Just the US\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = world) +\n    geom_sf() +\n    coord_sf(xlim = c(-125, -66), ylim = c(24.5, 50), \n             expand = FALSE)\n```\n\n::: {.cell-output-display}\n![](13-cs02-analysis_files/figure-html/unnamed-chunk-56-1.png){width=2100}\n:::\n:::\n\n\n## Monitor Data\n\nAdding in our monitors...\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = world) +\n    geom_sf() +\n    coord_sf(xlim = c(-125, -66), ylim = c(24.5, 50), \n             expand = FALSE)+\n    geom_point(data = pm, aes(x = lon, y = lat), size = 2, \n               shape = 23, fill = \"darkred\")\n```\n\n::: {.cell-output-display}\n![](13-cs02-analysis_files/figure-html/unnamed-chunk-57-1.png){width=2100}\n:::\n:::\n\n\n## County Lines\n\nAdding in county lines\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncounties <- sf::st_as_sf(maps::map(\"county\", plot = FALSE,\n                                   fill = TRUE))\n\ncounties\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 3076 features and 1 field\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -124.6813 ymin: 25.12993 xmax: -67.00742 ymax: 49.38323\nGeodetic CRS:  +proj=longlat +ellps=clrk66 +no_defs +type=crs\nFirst 10 features:\n                               ID                           geom\nalabama,autauga   alabama,autauga MULTIPOLYGON (((-86.50517 3...\nalabama,baldwin   alabama,baldwin MULTIPOLYGON (((-87.93757 3...\nalabama,barbour   alabama,barbour MULTIPOLYGON (((-85.42801 3...\nalabama,bibb         alabama,bibb MULTIPOLYGON (((-87.02083 3...\nalabama,blount     alabama,blount MULTIPOLYGON (((-86.9578 33...\nalabama,bullock   alabama,bullock MULTIPOLYGON (((-85.66866 3...\nalabama,butler     alabama,butler MULTIPOLYGON (((-86.8604 31...\nalabama,calhoun   alabama,calhoun MULTIPOLYGON (((-85.74313 3...\nalabama,chambers alabama,chambers MULTIPOLYGON (((-85.59416 3...\nalabama,cherokee alabama,cherokee MULTIPOLYGON (((-85.46812 3...\n```\n\n\n:::\n:::\n\n\n## The Map\n\n:::panel-tabset\n\n### Code\n\n::: {.cell}\n\n```{.r .cell-code}\nmonitors <- ggplot(data = world) +\n    geom_sf(data = counties, fill = NA, color = gray(.5))+\n      coord_sf(xlim = c(-125, -66), ylim = c(24.5, 50), \n             expand = FALSE) +\n    geom_point(data = pm, aes(x = lon, y = lat), size = 2, \n               shape = 23, fill = \"darkred\") +\n    ggtitle(\"Monitor Locations\") +\n    theme(axis.title.x=element_blank(),\n          axis.text.x = element_blank(),\n          axis.ticks.x = element_blank(),\n          axis.title.y = element_blank(),\n          axis.text.y = element_blank(),\n          axis.ticks.y = element_blank())\n```\n:::\n\n\n### Plot\n\n::: {.cell}\n::: {.cell-output-display}\n![](13-cs02-analysis_files/figure-html/unnamed-chunk-60-1.png){width=2100}\n:::\n:::\n\n\n:::\n\n## Counties \n\nWrangle counties:\n\n-   separate county and state into separate columns\n-   make title case\n-   combine with PM data\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncounties <- counties |> \n  tidyr::separate(ID, into = c(\"state\", \"county\"), sep = \",\") |> \n  dplyr::mutate(county = stringr::str_to_title(county))\n\nmap_data <- dplyr::inner_join(counties, pm, by = \"county\")\n```\n:::\n\n\n## Map: Truth\n\n::: panel-tabset\n### Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntruth <- ggplot(data = world) +\n  coord_sf(xlim = c(-125,-66),\n           ylim = c(24.5, 50),\n           expand = FALSE) +\n  geom_sf(data = map_data, aes(fill = value)) +\n  scale_fill_gradientn(colours = topo.colors(7),\n                       na.value = \"transparent\",\n                       breaks = c(0, 10, 20),\n                       labels = c(0, 10, 20),\n                       limits = c(0, 23.5),\n                       name = \"PM ug/m3\") +\n  ggtitle(\"True PM 2.5 levels\") +\n  theme(axis.title.x = element_blank(),\n        axis.text.x = element_blank(),\n        axis.ticks.x = element_blank(),\n        axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank())\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCoordinate system already present. Adding new coordinate system, which will\nreplace the existing one.\n```\n\n\n:::\n:::\n\n\n### Plot\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](13-cs02-analysis_files/figure-html/unnamed-chunk-62-1.png){width=2100}\n:::\n:::\n\n:::\n\n## Map: Predictions\n\n::: panel-tabset\n### Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# fit data\nRF_final_train_fit <- parsnip::fit(RF_tuned_wflow, data = train_pm)\nRF_final_test_fit <- parsnip::fit(RF_tuned_wflow, data = test_pm)\n\n# get predictions on training data\nvalues_pred_train <- predict(RF_final_train_fit, train_pm) |> \n  bind_cols(train_pm |> select(value, fips, county, id)) \n\n# get predictions on testing data\nvalues_pred_test <- predict(RF_final_test_fit, test_pm) |> \n  bind_cols(test_pm |> select(value, fips, county, id)) \nvalues_pred_test\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 292 × 5\n   .pred value fips  county     id       \n   <dbl> <dbl> <fct> <chr>      <fct>    \n 1  11.6  11.2 1033  Colbert    1033.1002\n 2  11.9  12.4 1055  Etowah     1055.001 \n 3  11.1  10.5 1069  Houston    1069.0003\n 4  13.9  15.6 1073  Jefferson  1073.0023\n 5  12.0  12.4 1073  Jefferson  1073.1005\n 6  11.3  11.1 1073  Jefferson  1073.1009\n 7  11.5  11.8 1073  Jefferson  1073.5003\n 8  11.0  10.0 1097  Mobile     1097.0003\n 9  11.9  12.0 1101  Montgomery 1101.0007\n10  12.9  13.2 1113  Russell    1113.0001\n# ℹ 282 more rows\n```\n\n\n:::\n\n```{.r .cell-code}\n# combine\nall_pred <- bind_rows(values_pred_test, values_pred_train)\n```\n:::\n\n\n### Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmap_data <- inner_join(counties, all_pred, by = \"county\")\n\npred <- ggplot(data = world) +\n  coord_sf(xlim = c(-125,-66),\n           ylim = c(24.5, 50),\n           expand = FALSE) +\n  geom_sf(data = map_data, aes(fill = .pred)) +\n  scale_fill_gradientn(colours = topo.colors(7),\n                       na.value = \"transparent\",\n                       breaks = c(0, 10, 20),\n                       labels = c(0, 10, 20),\n                       limits = c(0, 23.5),\n                       name = \"PM ug/m3\") +\n  ggtitle(\"Predicted PM 2.5 levels\") +\n  theme(axis.title.x=element_blank(),\n        axis.text.x=element_blank(),\n        axis.ticks.x=element_blank(),\n        axis.title.y=element_blank(),\n        axis.text.y=element_blank(),\n        axis.ticks.y=element_blank())\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCoordinate system already present. Adding new coordinate system, which will\nreplace the existing one.\n```\n\n\n:::\n:::\n\n\n### Plot\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](13-cs02-analysis_files/figure-html/unnamed-chunk-64-1.png){width=2100}\n:::\n:::\n\n:::\n\n## Final Plot\n\n:::panel-tabset\n\n### Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(patchwork)\n\nfinal_plot <- (truth/pred) + \n  plot_annotation(title = \"Machine Learning Methods Allow for Prediction of Air Pollution\", subtitle = \"A random forest model predicts true monitored levels of fine particulate matter (PM 2.5) air pollution based on\\ndata about population density and other predictors reasonably well, thus suggesting that we can use similar methods to predict levels\\nof pollution in places with poor monitoring\",\n                  theme = theme(plot.title = element_text(size =12, face = \"bold\"), \n                                plot.subtitle = element_text(size = 8)))\n```\n:::\n\n\n### Plot\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](13-cs02-analysis_files/figure-html/unnamed-chunk-66-1.png){width=2100}\n:::\n:::\n\n\n[❓ What do you learn from these results?]{style=\"background-color: #ADD8E6\"}\n\n## Your Case Study\n\n:::incremental\n- Can you copy + paste code directly from here to answer the question? Yes.\n- Do you have to present linear regression model *and* random forest? No\n- Should you present anything from the 12-regression notes? Probably not. (This is why HW03 and lab07 focus on regression)\n- Could you try an additional model as your extension? Yes!\n- Does that model have to be \"better\"? No! But, consider the story!\n- Could you try to identify the simplest, accurate model as an extension? Yes.\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}